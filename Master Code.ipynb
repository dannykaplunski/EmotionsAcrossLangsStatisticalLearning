{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ad326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave #for getting the wav file\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "import librosa #for doing all of the wavestuff\n",
    "import numpy as np #vector stuff\n",
    "import pandas as pd #dataframe\n",
    "import torch #tesnor storage of the matrix data\n",
    "import os \n",
    "import pandas as pd\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878f6a0",
   "metadata": {},
   "source": [
    "# All of the subroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae9996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets basic stats of the audio wave\n",
    "def get_mMa(clip):\n",
    "    max_amp = np.max(clip)\n",
    "    min_amp = np.min(clip)\n",
    "    mean_amp = np.mean(clip) \n",
    "    med_amp = np.median(clip)\n",
    "    return [max_amp, min_amp, mean_amp, med_amp]\n",
    "#0) max signal amplitude, 1) min signal amplitude, 2) mean signal amplitude, 3) median signal amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f13291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the fourier transform information\n",
    "def get_fourier(clip, samp_rate):\n",
    "    #Get the Fourier transform\n",
    "    fourier = np.fft.fft(clip)\n",
    "    #Get the spectrum\n",
    "    magspectrum = np.abs(fourier)\n",
    "    #get the frequencies that correspond to the fourier magnitudes\n",
    "    frequencies = abs(np.fft.fftfreq(len(fourier), d=1/samp_rate)) \n",
    "\n",
    "    #get the f with max magnitude\n",
    "    magmax = np.max(magspectrum) \n",
    "    #find the index\n",
    "    fmaxindex = np.where(magspectrum == magmax)\n",
    "    #get the corresponding frequency of maximum power at any point during the clip. If there are 2 points, pick one.\n",
    "    maxpf = frequencies[int(np.max(fmaxindex[0]))] \n",
    "\n",
    "    #define max f as highest f with 1/3 of the peak frequency\n",
    "    isrelmax = torch.tensor(magspectrum > magmax/3).to(torch.float)\n",
    "    relfs = torch.tensor(frequencies)*isrelmax #frequencies over 1/3 max mult by 1, others zeroed out\n",
    "    #maximum relevant frequency\n",
    "    maxf = max(relfs).numpy() \n",
    "    #define min f as lowest f with 1/3 of the peak (may often be 0)\n",
    "    minf = min(relfs).numpy()\n",
    "    #the BW of the magnitudes is max-min\n",
    "    bwfourier = maxf-minf\n",
    "    fourierout = [magmax, maxpf, maxf.item(), minf.item(), bwfourier]\n",
    "    return fourierout\n",
    "#0) max magnitude of fourier, 1) f for max magnitude, 2) highest relevant f, 3) lowest relevant f, 4) range (max-min) relevant f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27e13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get basic spectral stats\n",
    "def get_spec(clip, hoplen, samp_rate, nfft, maxf):\n",
    "    #Get BW\n",
    "    bw = np.max(librosa.feature.spectral_bandwidth(y=clip, sr=samp_rate, hop_length=hoplen)[0]) #sometimes gives 2 items in vector, one can be 0\n",
    "\n",
    "    \n",
    "    #Get the spectral rolloff\n",
    "    specroll = np.max(librosa.feature.spectral_rolloff(y= clip, sr=samp_rate, n_fft=nfft, hop_length=hoplen, roll_percent=0.85)[0])#sometimes gives 2 items in vector, one can be 0\n",
    "\n",
    "    \n",
    "    #get fundamental frequency\n",
    "    try:\n",
    "        f0 = np.nanmean(librosa.pyin(y=clip, fmin = 60, fmax = maxf, sr=samp_rate)[0])\n",
    "    except RuntimeWarning:\n",
    "    #sometimes it doesn't give a fundamental frequency and thinks it's nothing\n",
    "        f0 = 0\n",
    "        \n",
    "    spect = [bw, specroll, f0]\n",
    "    return spect\n",
    "#0) spect energy BW, 1) spectral rolloff 85% energy, 2) fundamental freq (f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2514e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frequencies with the max power (spectrogram) and spectral centroid\n",
    "def get_fpwr(clip, nfft, hoplen, f_res, samp_rate):\n",
    "    \n",
    "    fourier = librosa.stft(clip, n_fft=nfft, hop_length=hoplen)\n",
    "    #convert it from raw values to dB (log)\n",
    "    findb = librosa.amplitude_to_db(abs(fourier))\n",
    "    #0 is the frequency bins, 1 is the time stamp\n",
    "    #frequency corresponding to each row\n",
    "    f_bins = [i * f_res for i in range(fourier.shape[0])]\n",
    "    \n",
    "    #get the max energy value\n",
    "    overallmaxdb = np.max(findb) \n",
    "    #find the row it's in\n",
    "    overallindex = np.where(findb == overallmaxdb)\n",
    "    #get the corresponding frequency for that row\n",
    "    maxptf=f_bins[int(overallindex[0])] #frequency of maximum power at any point during the clip\n",
    "\n",
    "    #sum up the energy for all time periods for each row\n",
    "    rowsums = np.sum(fourier, axis=1)\n",
    "    #get the max energy value\n",
    "    rowmax = np.max(rowsums)\n",
    "    #find the row it's in\n",
    "    sumindex = np.where(rowsums == rowmax)\n",
    "    #get the corresponding frequency for that row\n",
    "    maxsumf=f_bins[int(sumindex[0])] #frequency of maximum power throughout the clip\n",
    "    \n",
    "    centroidvect = librosa.feature.spectral_centroid(y=clip, sr=samp_rate)\n",
    "    meancent = np.mean(centroidvect)\n",
    "    \n",
    "    return [maxptf, maxsumf, meancent]\n",
    "# 0) freq with max power at any point, 1) freq with max overall power, 2) spectral centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11664f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8f5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets differences and gradients between clip segment data\n",
    "def diffgrad(intensor):\n",
    "    cols = intensor.shape[1]\n",
    "    rows = intensor.shape[0]\n",
    "    zerost = torch.zeros(1, cols)\n",
    "    lastt = torch.cat((intensor, zerost), dim=0)\n",
    "    nextt = torch.cat((zerost, intensor), dim=0)\n",
    "    diffs = nextt-lastt\n",
    "    grads = nextt/lastt #need to replace nans with 0s\n",
    "    #remove the last line since it doesn't have meaning\n",
    "    tensoroutput = torch.cat((diffs[0:rows], grads[0:rows]), dim=1)\n",
    "    return tensoroutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e7792",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e9bce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the file \n",
    "#use Danny's subroutine not here to get all the filenames, this is just hardcoded for testing\n",
    "file_path = 'testfileest.wav'\n",
    "\n",
    "#Import it in librosa\n",
    "audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "#basic file info\n",
    "pts = len(audio_data)\n",
    "secs = pts/sample_rate\n",
    "\n",
    "\n",
    "#get data for the whole audio file************************\n",
    "\n",
    "#get the wave stats\n",
    "wavestats = get_mMa(audio_data)\n",
    "#0) max signal amplitude, 1) min signal amplitude, 2) mean signal amplitude, 3) median signal amplitude\n",
    "\n",
    "#get fourier stats\n",
    "fourierstats = get_fourier(audio_data, sample_rate)\n",
    "#0) max magnitude of fourier, 1) f for max magnitude, 2) highest relevant f, 3) lowest relevant f, 4) range (max-min) relevant f\n",
    "\n",
    "#setupfor spectral features:\n",
    "nfft = round(512*sample_rate/22050) #512 recommended for voice at 22050 Hz\n",
    "hoplwhole = sample_rate*3 #when we want data for the whole thing\n",
    "hopl = round(sample_rate/5) #number of audio samples between adjacent STFT columns, we want 200ms chunks for the clips\n",
    "#frequency resolution\n",
    "fres = sample_rate/nfft\n",
    "#max frequency\n",
    "maxf = fourierstats[2]\n",
    "\n",
    "#get spectral stats\n",
    "specstats = get_spec(audio_data, hoplwhole, sample_rate, nfft, maxf)\n",
    "#0) spect energy BW, 1) spectral rolloff 85% energy, 2) fundamental freq (f0)\n",
    "\n",
    "#get normalized range/f0\n",
    "rangef0 = fourierstats[4]/specstats[2]\n",
    "\n",
    "#get spectrogram stats\n",
    "spectrostats = get_fpwr(audio_data, nfft, hoplwhole, fres, sample_rate)\n",
    "# 0) freq with max power at any point, 1) freq with max overall power, 2) spectral centroid\n",
    "#and normalize them\n",
    "nspectrostats = [spectrostats[0]/spectrostats[2], spectrostats[1]/spectrostats[2]]\n",
    "\n",
    "#get chroma data\n",
    "chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate, hop_length=hoplwhole, n_fft=nfft)\n",
    "#can give 1 or 2 columns. need to either max or avg them, not sure which makes sense yet\n",
    "\n",
    "#get data for the different segments of the file************************\n",
    "\n",
    "#Makes a setup vector for segmenting the audio file into subclips\n",
    "n = 6 #number of sections to split into +1\n",
    "#the shortest filess are 1 second and we don't want clips shorter than 200 ms since that's what the human ear picks up\n",
    "pps = np.round(pts/n) #points per section, with the last section getting the extras or shorted\n",
    "cutoffs = [int(pps * i) for i in range(0, n-1)]\n",
    "cutoffs.append(int(pts))\n",
    "\n",
    "\n",
    "#Run all of the subroutines to get the data for the segmented audio clips\n",
    "segdata = []\n",
    "for i in range(0, n-1):\n",
    "    #make the shortened clip\n",
    "    shortclip = audio_data[cutoffs[i]:cutoffs[i+1]]\n",
    "    \n",
    "    #run it through the subroutines in order to get the data for each\n",
    "    clipdata= get_mMa(shortclip) #4 columns\n",
    "    #add wave normalization:\n",
    "    n1 = clipdata[0]/max(wavestats[0], np.abs(wavestats[1])) #to overall peak\n",
    "    n2 = clipdata[1]/max(wavestats[0], np.abs(wavestats[1])) #to overall peak\n",
    "    n3 = clipdata[2]/wavestats[2] #to overall avg mag\n",
    "    n4 = clipdata[3]/wavestats[3] #to overall median mag\n",
    "    clipndata = [n1, n2, n3, n4] #4 columns\n",
    "    \n",
    "    clipfourier = get_fourier(shortclip, sample_rate) #5 columns\n",
    "    #add fourier normalization\n",
    "    clipnfourier = [clipfourier[1]/fourierstats[1] , clipfourier[2]/fourierstats[2]] #2 columns, normalized to overall\n",
    "    \n",
    "    clipspec = get_spec(shortclip, hopl, sample_rate, nfft, maxf) #3 columns\n",
    "    cliprangef0 = clipfourier[4]/clipspec[2] #single value\n",
    "    clipspectro = get_fpwr(shortclip, nfft, hopl, fres, sample_rate) #3 columns\n",
    "    #add spectral normalization:\n",
    "    clipnspectro = [clipspectro[0]/clipspectro[2], clipspectro[1]/clipspectro[2]] #2 columns, normalized to f0 of clip\n",
    "    \n",
    "    \n",
    "    #Outputs are all lists. Combine into 1 long row list and append as new row.\n",
    "    segdata.append(clipdata + clipfourier + clipspec + [cliprangef0] + clipspectro + clipnspectro + clipndata + clipnfourier) #18 columns\n",
    "    #0-3: wave stats, 4-8: fourier stats, 9-11: spectrum stats, 12: norm range, \n",
    "    #13-15: spectrogram stats, 16-17: normalized spectrogram, \n",
    "    #18-21: wave stats norm to overall, 22-23: fourier norm to overall\n",
    "    \n",
    "segmenttensor = torch.tensor(segdata)    \n",
    "\n",
    "\n",
    "#get data for changes between segments************************\n",
    "\n",
    "dg = diffgrad(segmenttensor[:,0:17]) #taking the diff of grad between data normalized to the overall would just be a linear combo of the data\n",
    "\n",
    "\n",
    "#make one big output for the whole file*************************\n",
    "#we have all of the data from the whole audio file, the data for the segments, and the data for the change between segments\n",
    "#we want to flatten it into a single row\n",
    "wholedata = torch.tensor(wavestats + fourierstats + specstats + [rangef0] + spectrostats + nspectrostats)\n",
    "segmentdata = torch.reshape(torch.cat((segmenttensor, dg), dim=1), (1,290))[0]\n",
    "\n",
    "final_output = torch.cat((wholedata, segmentdata), dim=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
